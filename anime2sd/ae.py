import os
os.environ["PYTORCH_INDUCTOR_CACHE_DIR"] = "/home/user/cache"
import torch
import torch.distributed as dist
import torch.multiprocessing as mp
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler
import torch.backends.cudnn as cudnn
from torch.utils.data import Dataset, DataLoader
from aesthetic_predictor_v2_5 import convert_v2_5_from_siglip
import pillow_jxl
from PIL import Image
import argparse
from tqdm import tqdm

def setup_optimizations():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—Å–µ—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π PyTorch"""
    if torch.cuda.is_available():
        # cuDNN –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        cudnn.enabled = True
        cudnn.benchmark = True  # –ê–≤—Ç–æ—Ç—é–Ω–∏–Ω–≥ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª—É—á—à–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
        cudnn.deterministic = False  # –í—ã–∫–ª—é—á–∞–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        
        # TF32 –¥–ª—è Ampere –∏ –Ω–æ–≤–µ–µ
        major, _ = torch.cuda.get_device_capability()
        if major >= 8:
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            print("‚úÖ TF32 enabled")
        
        # PyTorch 2.0 SDPA (Flash Attention, Memory Efficient Attention)
        torch.backends.cuda.enable_flash_sdp(True)
        torch.backends.cuda.enable_mem_efficient_sdp(True)
        torch.backends.cuda.enable_math_sdp(True)
        print("‚úÖ PyTorch SDPA (Flash Attention / Memory Efficient) enabled")
        
        # –û—Ç–∫–ª—é—á–∞–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        torch.use_deterministic_algorithms(False)

def setup_ddp(rank, world_size):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DDP"""
    os.environ['MASTER_ADDR'] = 'localhost'
    os.environ['MASTER_PORT'] = '12356'
    dist.init_process_group("nccl", rank=rank, world_size=world_size)
    torch.cuda.set_device(rank)

def cleanup_ddp():
    """–û—á–∏—Å—Ç–∫–∞ DDP"""
    if dist.is_initialized():
        dist.destroy_process_group()

class ImageDataset(Dataset):
    def __init__(self, image_paths, preprocessor):
        self.image_paths = image_paths
        self.preprocessor = preprocessor

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        try:
            image = Image.open(image_path).convert("RGB")
            pixel_values = self.preprocessor(images=[image], return_tensors="pt").pixel_values.squeeze()
            return image_path, pixel_values
        except Exception as e:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            print(f"Error loading {image_path}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —á–µ—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ fallback
            dummy_image = Image.new('RGB', (224, 224), (0, 0, 0))
            pixel_values = self.preprocessor(images=[dummy_image], return_tensors="pt").pixel_values.squeeze()
            return image_path, pixel_values

def setup_model(device, use_ddp=False, rank=0):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ —Å –∫–æ–º–ø–∏–ª—è—Ü–∏–µ–π –∏ DDP"""
    if rank == 0 or not use_ddp:
        print("Loading model...")
    
    model, preprocessor = convert_v2_5_from_siglip(
        trust_remote_code=True,
    )
    
    model = model.to(torch.bfloat16)
    model = model.to(device)
    model.eval()
    
    # torch.compile —Å max-autotune –í–°–ï–ì–î–ê –≤–∫–ª—é—á–µ–Ω
    if rank == 0 or not use_ddp:
        print("üî• Compiling model with torch.compile(mode='max-autotune')")
    
    try:
        compiled_model = torch.compile(
            model,
            mode="max-autotune",
            fullgraph=False
        )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
        with torch.inference_mode():
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞ –∏–∑ preprocessor
            dummy_image = Image.new('RGB', (224, 224), (0, 0, 0))
            test_input = preprocessor(images=[dummy_image], return_tensors="pt").pixel_values
            test_input = test_input.to(torch.bfloat16).to(device)
            _ = compiled_model(test_input)
        
        if rank == 0 or not use_ddp:
            print("‚úÖ Model compiled successfully with max-autotune")
        model = compiled_model
    except Exception as e:
        if rank == 0 or not use_ddp:
            print(f"‚ö†Ô∏è  Compilation failed: {e}")
            print("Using uncompiled model")
    
    # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ DDP –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if use_ddp:
        model = DDP(model, device_ids=[rank], output_device=rank)
        if rank == 0:
            print(f"‚úÖ DDP initialized on {dist.get_world_size()} GPUs")
    
    return model, preprocessor

def find_image_paths(directory):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    image_paths = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.webp', '.bmp', '.jxl')):
                image_paths.append(os.path.join(root, file))
    return image_paths

def get_optimal_worker_count(world_size):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ workers"""
    cpu_count = os.cpu_count()
    # –ü—Ä–∏–º–µ—Ä–Ω–æ 4-8 workers –Ω–∞ GPU, –Ω–æ –Ω–µ –±–æ–ª—å—à–µ —á–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ CPU
    workers_per_gpu = min(8, cpu_count // world_size)
    return max(1, workers_per_gpu)

def process_images_worker(rank, world_size, input_dir, threshold, base_batch_size):
    """Worker —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è DDP –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    use_ddp = world_size > 1
    
    if use_ddp:
        setup_ddp(rank, world_size)
    
    device = f"cuda:{rank}"
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏
    model, preprocessor = setup_model(device, use_ddp, rank)
    
    # –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    image_paths = find_image_paths(input_dir)
    
    if len(image_paths) == 0:
        if rank == 0:
            print(f"No images found in {input_dir}")
        if use_ddp:
            cleanup_ddp()
        return
    
    if rank == 0 or not use_ddp:
        print(f"\nFound {len(image_paths)} images to process")
    
    # –°–æ–∑–¥–∞–µ–º dataset
    dataset = ImageDataset(image_paths, preprocessor)
    
    # Batch size –Ω–∞ GPU
    per_gpu_batch_size = base_batch_size // world_size if use_ddp else base_batch_size
    effective_batch_size = per_gpu_batch_size * world_size if use_ddp else base_batch_size
    
    # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ workers
    num_workers = get_optimal_worker_count(world_size)
    
    if rank == 0 or not use_ddp:
        if use_ddp:
            print(f"üöÄ Using {world_size} GPUs")
            print(f"üìä Effective batch size: {effective_batch_size} (per GPU: {per_gpu_batch_size})")
        else:
            print(f"üìä Batch size: {base_batch_size}")
        print(f"üë∑ Number of workers: {num_workers}")
    
    # –°–æ–∑–¥–∞–µ–º sampler –¥–ª—è DDP
    sampler = DistributedSampler(dataset, shuffle=False, drop_last=False) if use_ddp else None
    
    dataloader = DataLoader(
        dataset,
        batch_size=per_gpu_batch_size,
        num_workers=num_workers,
        pin_memory=True,
        sampler=sampler,
        shuffle=False,
        persistent_workers=True if num_workers > 0 else False,
        prefetch_factor=2 if num_workers > 0 else None
    )
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    local_deleted_count = 0
    local_kept_count = 0
    local_results = []  # –î–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    with torch.inference_mode():
        for batch_paths, pixel_values in tqdm(dataloader, 
                                             desc=f"GPU {rank}" if use_ddp else "Processing",
                                             disable=use_ddp and rank != 0):
            pixel_values = pixel_values.to(torch.bfloat16).to(device, non_blocking=True)
            
            scores = model(pixel_values).logits.squeeze()
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É—á–∞–π –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –±–∞—Ç—á–∞
            if scores.dim() == 0:
                scores = scores.unsqueeze(0)
            
            scores = scores.float().cpu().numpy()
            
            for path, score in zip(batch_paths, scores):
                local_results.append((path, score))
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ –≤—Å–µ—Ö GPU
    if use_ddp:
        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
        dist.barrier()
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        gathered_results = [None] * world_size
        dist.all_gather_object(gathered_results, local_results)
        
        # –¢–æ–ª—å–∫–æ rank 0 –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if rank == 0:
            all_results = []
            for results in gathered_results:
                all_results.extend(results)
        else:
            cleanup_ddp()
            return
    else:
        all_results = local_results
    
    # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã (—Ç–æ–ª—å–∫–æ rank 0)
    deleted_count = 0
    kept_count = 0
    
    print("\n" + "="*80)
    print("Processing results:")
    print("="*80)
    
    for path, score in all_results:
        filename = os.path.basename(path)
        if score < threshold:
            try:
                os.remove(path)
                deleted_count += 1
                print(f"‚ùå Deleted {filename}: Score {score:.2f}")
            except Exception as e:
                print(f"‚ö†Ô∏è  Error deleting {filename}: {e}")
        else:
            kept_count += 1
            print(f"‚úÖ Kept {filename}: Score {score:.2f}")
    
    print("\n" + "="*80)
    print("Processing complete:")
    print("="*80)
    print(f"Total images processed: {len(all_results)}")
    print(f"Images deleted: {deleted_count}")
    print(f"Images kept: {kept_count}")
    print(f"Deletion rate: {deleted_count/len(all_results)*100:.1f}%")
    print("="*80)
    
    if use_ddp:
        cleanup_ddp()

def main(input_dir, threshold, batch_size):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º multi-GPU"""
    # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ
    print("="*80)
    print("System Information:")
    print("="*80)
    print(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA version: {torch.version.cuda}")
        print(f"cuDNN version: {torch.backends.cudnn.version()}")
        print(f"cuDNN enabled: {torch.backends.cudnn.enabled}")
        print(f"cuDNN benchmark mode: {torch.backends.cudnn.benchmark}")
        print(f"GPU count: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
    print("="*80)
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤—Å–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    setup_optimizations()
    
    world_size = torch.cuda.device_count() if torch.cuda.is_available() else 1
    
    if world_size == 0:
        raise RuntimeError("No GPU devices found!")
    
    if world_size > 1:
        # Multi-GPU —Å DDP
        print(f"\nüöÄ Launching DDP with {world_size} GPUs\n")
        mp.spawn(
            process_images_worker,
            args=(world_size, input_dir, threshold, batch_size),
            nprocs=world_size,
            join=True
        )
    else:
        # Single GPU
        print(f"\nüéØ Using single GPU mode\n")
        process_images_worker(0, 1, input_dir, threshold, batch_size)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Process images and delete those below a certain aesthetic score.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument("input_dir", help="Path to the directory containing images")
    parser.add_argument("--threshold", type=float, default=4.2, 
                       help="Threshold score for deletion")
    parser.add_argument("--batch-size", type=int, default=128,
                       help="Total batch size (will be divided by number of GPUs)")
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    if not os.path.isdir(args.input_dir):
        print(f"Error: Directory '{args.input_dir}' does not exist!")
        exit(1)
    
    main(args.input_dir, args.threshold, args.batch_size)